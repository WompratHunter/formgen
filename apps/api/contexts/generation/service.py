import json
import os
from openai import OpenAI
from pydantic import ValidationError
from contexts.generation.schemas import LLMFormOutput
from shared.errors import GenerationOutputError

SYSTEM_PROMPT = """You are a form schema generator. Given a plain English description of a form, return a JSON object matching this schema exactly (no markdown, no commentary — raw JSON only):

{
  "name": "string — short descriptive name for the form",
  "description": "string — one sentence describing the form's purpose",
  "fields": [
    {
      "key": "snake_case_unique_key",
      "type": "one of: text, email, password, number, tel, url, textarea, select, checkbox, radio, date, slider, toggle",
      "label": "Human-readable label",
      "placeholder": "optional placeholder text",
      "hint": "optional helper text shown below the field",
      "required": true or false,
      "options": [{"label": "Display", "value": "value"}]  // only for select or radio fields
    }
  ],
  "layout": {
    "columns": 1, 2, 3, or 4
  }
}

Rules:
- Every field key must be unique and in snake_case
- Select and radio fields MUST have at least one option
- Use 1 column for simple forms, 2 for medium, 3-4 for complex/wide forms
- Always include an email field for contact forms
- Return ONLY the JSON object — no other text
"""


class GenerationService:
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        base_url = os.getenv("LLM_BASE_URL")
        self.model = os.getenv("LLM_MODEL", "gemini-2.5-flash")
        self.client = OpenAI(api_key=api_key, base_url=base_url) if api_key else None

    def generate(self, prompt: str) -> LLMFormOutput:
        if not self.client:
            return self._stub(prompt)

        response = self.client.chat.completions.create(
            model=self.model,
            max_tokens=2048,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
        )
        raw = response.choices[0].message.content.strip()

        try:
            data = json.loads(raw)
        except json.JSONDecodeError as exc:
            raise GenerationOutputError(
                f"LLM returned non-JSON output. Parse error: {exc}. "
                f"Raw output (first 200 chars): {raw[:200]}"
            ) from exc

        try:
            return LLMFormOutput(**data)
        except (ValidationError, TypeError) as exc:
            raise GenerationOutputError(
                f"LLM output did not match expected schema: {exc}"
            ) from exc

    def _stub(self, prompt: str) -> LLMFormOutput:
        """Returns a deterministic stub when no API key is configured."""
        return LLMFormOutput(
            name="Contact Form",
            description="A simple contact form generated from prompt: " + prompt[:60],
            fields=[
                {"key": "full_name", "type": "text", "label": "Full Name", "placeholder": "Your name", "required": True},
                {"key": "email", "type": "email", "label": "Email Address", "placeholder": "you@example.com", "required": True},
                {"key": "message", "type": "textarea", "label": "Message", "placeholder": "Write your message here...", "required": True},
            ],
            layout={"columns": 1},
        )
